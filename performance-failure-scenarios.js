/**
 * Performance Failure Scenarios - Enhanced failure testing and recovery validation
 * Tests system performance under failure conditions and recovery scenarios
 * 
 * Enhanced Claude Development Protocol v1.4 - Phase 3: Refinement
 */

const redis = require('redis');
const { Client } = require('pg');
const config = require('./config');
const PerformanceTestSuite = require('./performance-test-suite');

class PerformanceFailureScenarios {
    constructor() {
        this.redisClient = null;
        this.pgClient = null;
        this.backupRedisClient = null;
        this.testSuite = null;
        
        // Failure scenario configuration
        this.failureConfig = {
            scenarios: {
                redis_disconnect: {
                    description: 'Redis connection failure and recovery',
                    duration: 60000,
                    recoveryTime: 30000
                },
                postgres_overload: {
                    description: 'PostgreSQL connection exhaustion',
                    duration: 120000,
                    connectionLimit: 5
                },
                network_latency: {
                    description: 'Simulated network latency spikes',
                    latencyMs: [100, 500, 1000],
                    duration: 180000
                },
                memory_pressure: {
                    description: 'Memory pressure and garbage collection',
                    memoryPressureMB: 400,
                    duration: 300000
                },
                rate_limit_exhaustion: {
                    description: 'Rate limiting system under extreme load',
                    overloadFactor: 10,
                    duration: 120000
                },
                multi_instance_partition: {
                    description: 'Network partition between instances',
                    duration: 180000,
                    partitionInstances: 2
                }
            },
            
            // Performance thresholds during failures
            failureThresholds: {
                maxLatencyMs: 50,        // Relaxed during failures
                minThroughput: 50,       // Reduced throughput acceptable
                maxErrorRate: 5,         // 5% error rate acceptable during failures
                recoveryTimeMs: 30000    // Maximum recovery time
            },
            
            // Recovery validation criteria
            recoveryValidation: {
                latencyRecoveryMs: 15,   // Must return to <15ms after recovery
                throughputRecovery: 90,  // 90% of normal throughput
                stabilityPeriodMs: 60000 // 1 minute stable operation required
            }
        };
        
        // Failure state tracking
        this.failureState = {
            activeFailures: new Set(),
            failureHistory: [],
            recoveryMetrics: [],
            performanceBaseline: null
        };
        
        console.log('💥 Performance Failure Scenarios initialized');
    }
    
    async init() {
        await this.setupDatabase();\n        await this.setupTestSuite();\n        await this.establishPerformanceBaseline();\n        \n        console.log('🚀 Failure scenarios ready for testing');\n    }\n    \n    async setupDatabase() {\n        // Primary Redis connection\n        this.redisClient = redis.createClient({\n            url: process.env.REDIS_URL || 'redis://localhost:6379',\n            socket: {\n                connectTimeout: 5000,\n                commandTimeout: 5000\n            }\n        });\n        \n        await this.redisClient.connect();\n        \n        // Backup Redis connection for failure testing\n        this.backupRedisClient = redis.createClient({\n            url: process.env.REDIS_URL || 'redis://localhost:6379'\n        });\n        \n        await this.backupRedisClient.connect();\n        \n        // PostgreSQL connection\n        try {\n            this.pgClient = new Client({\n                connectionString: process.env.DATABASE_URL || 'postgresql://localhost:5432/twitch_cv',\n                connectionTimeoutMillis: 5000,\n                query_timeout: 10000\n            });\n            await this.pgClient.connect();\n            console.log('✅ Failure testing connected to databases');\n        } catch (err) {\n            console.log('⚠️ PostgreSQL unavailable for failure testing');\n            this.pgClient = null;\n        }\n    }\n    \n    async setupTestSuite() {\n        this.testSuite = new PerformanceTestSuite();\n        await this.testSuite.init();\n    }\n    \n    async establishPerformanceBaseline() {\n        console.log('📊 Establishing performance baseline...');\n        \n        // Run baseline performance test\n        const baselineResults = await this.testSuite.runTest('sustained', {\n            duration: 60000,\n            users: 50\n        });\n        \n        this.failureState.performanceBaseline = {\n            latency: baselineResults.analysis.latencyAnalysis,\n            throughput: baselineResults.analysis.throughputAnalysis,\n            resources: baselineResults.analysis.resourceAnalysis,\n            timestamp: Date.now()\n        };\n        \n        console.log('📊 Performance baseline established:', {\n            avgLatency: this.failureState.performanceBaseline.latency.mean,\n            throughput: this.failureState.performanceBaseline.throughput.overallThroughput\n        });\n    }\n    \n    // ===== Failure Scenario Implementations =====\n    \n    async runFailureScenario(scenarioName) {\n        const scenario = this.failureConfig.scenarios[scenarioName];\n        if (!scenario) {\n            throw new Error(`Unknown failure scenario: ${scenarioName}`);\n        }\n        \n        console.log(`💥 Running failure scenario: ${scenario.description}`);\n        \n        const testId = `failure_${scenarioName}_${Date.now()}`;\n        this.failureState.activeFailures.add(scenarioName);\n        \n        try {\n            // Phase 1: Pre-failure performance measurement\n            const preFailureMetrics = await this.measurePreFailurePerformance();\n            \n            // Phase 2: Introduce failure\n            const failurePromise = this.introduceFailure(scenarioName, scenario);\n            \n            // Phase 3: Performance testing during failure\n            const duringFailureMetrics = await this.testPerformanceDuringFailure(scenario);\n            \n            // Phase 4: Recovery\n            await failurePromise; // Wait for failure to be resolved\n            const recoveryMetrics = await this.measureRecoveryPerformance(scenario);\n            \n            // Phase 5: Post-recovery validation\n            const postRecoveryMetrics = await this.validatePostRecoveryPerformance();\n            \n            // Analyze results\n            const analysis = this.analyzeFailureResults({\n                scenario: scenarioName,\n                preFailure: preFailureMetrics,\n                duringFailure: duringFailureMetrics,\n                recovery: recoveryMetrics,\n                postRecovery: postRecoveryMetrics\n            });\n            \n            // Store results\n            await this.storeFailureResults(testId, analysis);\n            \n            console.log(`✅ Failure scenario completed: ${scenarioName}`);\n            return analysis;\n            \n        } catch (err) {\n            console.error(`❌ Failure scenario error: ${scenarioName}`, err);\n            throw err;\n        } finally {\n            this.failureState.activeFailures.delete(scenarioName);\n        }\n    }\n    \n    async introduceFailure(scenarioName, scenario) {\n        switch (scenarioName) {\n            case 'redis_disconnect':\n                return this.simulateRedisDisconnection(scenario);\n            case 'postgres_overload':\n                return this.simulatePostgreSQLOverload(scenario);\n            case 'network_latency':\n                return this.simulateNetworkLatency(scenario);\n            case 'memory_pressure':\n                return this.simulateMemoryPressure(scenario);\n            case 'rate_limit_exhaustion':\n                return this.simulateRateLimitExhaustion(scenario);\n            case 'multi_instance_partition':\n                return this.simulateNetworkPartition(scenario);\n            default:\n                throw new Error(`Unknown failure type: ${scenarioName}`);\n        }\n    }\n    \n    async simulateRedisDisconnection(scenario) {\n        console.log('💥 Simulating Redis disconnection...');\n        \n        // Disconnect primary Redis client\n        await this.redisClient.quit();\n        \n        // Wait for failure duration\n        await this.sleep(scenario.duration);\n        \n        // Reconnect\n        console.log('🔄 Reconnecting Redis...');\n        this.redisClient = redis.createClient({\n            url: process.env.REDIS_URL || 'redis://localhost:6379'\n        });\n        await this.redisClient.connect();\n        \n        // Allow recovery time\n        await this.sleep(scenario.recoveryTime);\n        \n        console.log('✅ Redis reconnection completed');\n    }\n    \n    async simulatePostgreSQLOverload(scenario) {\n        console.log('💥 Simulating PostgreSQL connection exhaustion...');\n        \n        const overloadConnections = [];\n        \n        try {\n            // Create connections to exhaust pool\n            for (let i = 0; i < scenario.connectionLimit * 2; i++) {\n                const client = new Client({\n                    connectionString: process.env.DATABASE_URL || 'postgresql://localhost:5432/twitch_cv'\n                });\n                \n                try {\n                    await client.connect();\n                    overloadConnections.push(client);\n                } catch (err) {\n                    // Expected when pool is exhausted\n                    console.log(`Connection ${i + 1} failed (expected): ${err.message}`);\n                }\n            }\n            \n            console.log(`💥 Created ${overloadConnections.length} connections to overload PostgreSQL`);\n            \n            // Keep connections open for failure duration\n            await this.sleep(scenario.duration);\n            \n        } finally {\n            // Clean up overload connections\n            console.log('🔄 Cleaning up PostgreSQL overload...');\n            for (const client of overloadConnections) {\n                try {\n                    await client.end();\n                } catch (err) {\n                    // Ignore cleanup errors\n                }\n            }\n            console.log('✅ PostgreSQL overload cleaned up');\n        }\n    }\n    \n    async simulateNetworkLatency(scenario) {\n        console.log('💥 Simulating network latency spikes...');\n        \n        const originalQuery = this.pgClient?.query;\n        const originalRedisCommands = new Map();\n        \n        // Inject latency into PostgreSQL queries\n        if (this.pgClient) {\n            this.pgClient.query = async function(...args) {\n                const latency = scenario.latencyMs[Math.floor(Math.random() * scenario.latencyMs.length)];\n                await sleep(latency);\n                return originalQuery.apply(this, args);\n            };\n        }\n        \n        // Inject latency into Redis commands\n        ['get', 'set', 'hGet', 'hSet', 'publish'].forEach(command => {\n            const original = this.redisClient[command];\n            if (original) {\n                originalRedisCommands.set(command, original);\n                this.redisClient[command] = async function(...args) {\n                    const latency = scenario.latencyMs[Math.floor(Math.random() * scenario.latencyMs.length)];\n                    await sleep(latency);\n                    return original.apply(this, args);\n                };\n            }\n        });\n        \n        // Keep latency injection for scenario duration\n        await this.sleep(scenario.duration);\n        \n        // Restore original methods\n        console.log('🔄 Removing network latency simulation...');\n        if (this.pgClient) {\n            this.pgClient.query = originalQuery;\n        }\n        \n        originalRedisCommands.forEach((original, command) => {\n            this.redisClient[command] = original;\n        });\n        \n        console.log('✅ Network latency simulation removed');\n        \n        function sleep(ms) {\n            return new Promise(resolve => setTimeout(resolve, ms));\n        }\n    }\n    \n    async simulateMemoryPressure(scenario) {\n        console.log('💥 Simulating memory pressure...');\n        \n        const memoryHogs = [];\n        const targetMemoryMB = scenario.memoryPressureMB;\n        const chunkSizeMB = 10;\n        \n        try {\n            // Allocate memory to create pressure\n            while (this.getCurrentMemoryUsageMB() < targetMemoryMB) {\n                const chunk = Buffer.alloc(chunkSizeMB * 1024 * 1024, 'a');\n                memoryHogs.push(chunk);\n                await this.sleep(100); // Small delay to allow monitoring\n            }\n            \n            console.log(`💥 Memory pressure created: ${this.getCurrentMemoryUsageMB()}MB`);\n            \n            // Maintain pressure for scenario duration\n            await this.sleep(scenario.duration);\n            \n        } finally {\n            // Release memory pressure\n            console.log('🔄 Releasing memory pressure...');\n            memoryHogs.length = 0; // Clear references\n            \n            if (global.gc) {\n                global.gc();\n            }\n            \n            console.log(`✅ Memory pressure released: ${this.getCurrentMemoryUsageMB()}MB`);\n        }\n    }\n    \n    async simulateRateLimitExhaustion(scenario) {\n        console.log('💥 Simulating rate limiting exhaustion...');\n        \n        const normalLoad = 100; // Normal user count\n        const overloadUsers = normalLoad * scenario.overloadFactor;\n        \n        // Generate extreme load to exhaust rate limiting\n        const overloadTest = await this.testSuite.runTest('burst', {\n            duration: scenario.duration,\n            users: overloadUsers,\n            rate: 10.0 // Very high rate\n        });\n        \n        console.log('✅ Rate limiting exhaustion test completed');\n        return overloadTest;\n    }\n    \n    async simulateNetworkPartition(scenario) {\n        console.log('💥 Simulating network partition between instances...');\n        \n        // Create isolated Redis namespace for partition simulation\n        const partitionKey = `partition_${Date.now()}`;\n        \n        // Simulate instance isolation by using separate Redis keys\n        await this.redisClient.hSet(`instance:partition:${partitionKey}`, {\n            status: 'partitioned',\n            timestamp: Date.now().toString(),\n            instances: scenario.partitionInstances.toString()\n        });\n        \n        // Run coordinated test with artificial partition\n        await this.testSuite.runTest('multiInstance', {\n            duration: scenario.duration,\n            partitionSimulation: true,\n            partitionKey\n        });\n        \n        // Remove partition simulation\n        await this.redisClient.del(`instance:partition:${partitionKey}`);\n        \n        console.log('✅ Network partition simulation completed');\n    }\n    \n    // ===== Performance Measurement During Failures =====\n    \n    async measurePreFailurePerformance() {\n        console.log('📊 Measuring pre-failure performance...');\n        \n        const preFailureTest = await this.testSuite.runTest('sustained', {\n            duration: 30000,\n            users: 50\n        });\n        \n        return {\n            latency: preFailureTest.analysis.latencyAnalysis,\n            throughput: preFailureTest.analysis.throughputAnalysis,\n            resources: preFailureTest.analysis.resourceAnalysis,\n            timestamp: Date.now()\n        };\n    }\n    \n    async testPerformanceDuringFailure(scenario) {\n        console.log('📊 Testing performance during failure...');\n        \n        const duringFailureTest = await this.testSuite.runTest('sustained', {\n            duration: Math.min(scenario.duration, 60000), // Max 1 minute during failure\n            users: 30, // Reduced load during failure\n            allowFailures: true\n        });\n        \n        return {\n            latency: duringFailureTest.analysis.latencyAnalysis,\n            throughput: duringFailureTest.analysis.throughputAnalysis,\n            resources: duringFailureTest.analysis.resourceAnalysis,\n            errors: duringFailureTest.analysis.errorAnalysis || { rate: 0 },\n            timestamp: Date.now()\n        };\n    }\n    \n    async measureRecoveryPerformance(scenario) {\n        console.log('📊 Measuring recovery performance...');\n        \n        const recoveryStartTime = Date.now();\n        let recoveryTime = 0;\n        let stabilityAchieved = false;\n        \n        // Monitor recovery with periodic measurements\n        while (recoveryTime < this.failureConfig.failureThresholds.recoveryTimeMs) {\n            const quickTest = await this.runQuickPerformanceCheck();\n            \n            // Check if performance has recovered\n            if (this.isPerformanceRecovered(quickTest)) {\n                stabilityAchieved = true;\n                break;\n            }\n            \n            await this.sleep(5000); // Check every 5 seconds\n            recoveryTime = Date.now() - recoveryStartTime;\n        }\n        \n        return {\n            recoveryTime,\n            stabilityAchieved,\n            finalMetrics: await this.runQuickPerformanceCheck(),\n            timestamp: Date.now()\n        };\n    }\n    \n    async validatePostRecoveryPerformance() {\n        console.log('📊 Validating post-recovery performance...');\n        \n        // Wait for stability period\n        await this.sleep(this.failureConfig.recoveryValidation.stabilityPeriodMs);\n        \n        // Run comprehensive test to validate full recovery\n        const postRecoveryTest = await this.testSuite.runTest('sustained', {\n            duration: 60000,\n            users: 50\n        });\n        \n        return {\n            latency: postRecoveryTest.analysis.latencyAnalysis,\n            throughput: postRecoveryTest.analysis.throughputAnalysis,\n            resources: postRecoveryTest.analysis.resourceAnalysis,\n            timestamp: Date.now()\n        };\n    }\n    \n    async runQuickPerformanceCheck() {\n        // Quick 10-second performance check\n        const quickTest = await this.testSuite.runTest('sustained', {\n            duration: 10000,\n            users: 10\n        });\n        \n        return {\n            avgLatency: quickTest.analysis.latencyAnalysis.mean,\n            throughput: quickTest.analysis.throughputAnalysis.overallThroughput,\n            errorRate: quickTest.analysis.errorAnalysis?.rate || 0\n        };\n    }\n    \n    isPerformanceRecovered(metrics) {\n        const baseline = this.failureState.performanceBaseline;\n        if (!baseline) return false;\n        \n        const latencyRecovered = metrics.avgLatency <= this.failureConfig.recoveryValidation.latencyRecoveryMs;\n        const throughputRecovered = metrics.throughput >= (baseline.throughput.overallThroughput * this.failureConfig.recoveryValidation.throughputRecovery / 100);\n        const errorRateAcceptable = metrics.errorRate <= 1; // 1% error rate\n        \n        return latencyRecovered && throughputRecovered && errorRateAcceptable;\n    }\n    \n    // ===== Analysis and Reporting =====\n    \n    analyzeFailureResults(results) {\n        const analysis = {\n            scenario: results.scenario,\n            summary: this.generateFailureSummary(results),\n            performanceImpact: this.analyzePerformanceImpact(results),\n            recoveryAnalysis: this.analyzeRecoveryCharacteristics(results),\n            complianceCheck: this.checkFailureCompliance(results),\n            recommendations: this.generateFailureRecommendations(results)\n        };\n        \n        return analysis;\n    }\n    \n    generateFailureSummary(results) {\n        return {\n            scenario: results.scenario,\n            testDuration: results.postRecovery.timestamp - results.preFailure.timestamp,\n            recoveryTime: results.recovery.recoveryTime,\n            stabilityAchieved: results.recovery.stabilityAchieved,\n            performanceRecovered: this.isPerformanceRecovered(results.recovery.finalMetrics)\n        };\n    }\n    \n    analyzePerformanceImpact(results) {\n        const preFailure = results.preFailure;\n        const duringFailure = results.duringFailure;\n        const postRecovery = results.postRecovery;\n        \n        return {\n            latencyImpact: {\n                beforeFailure: preFailure.latency.mean,\n                duringFailure: duringFailure.latency.mean,\n                afterRecovery: postRecovery.latency.mean,\n                degradationPercent: ((duringFailure.latency.mean - preFailure.latency.mean) / preFailure.latency.mean) * 100,\n                recoveryPercent: ((postRecovery.latency.mean - preFailure.latency.mean) / preFailure.latency.mean) * 100\n            },\n            throughputImpact: {\n                beforeFailure: preFailure.throughput.overallThroughput,\n                duringFailure: duringFailure.throughput.overallThroughput,\n                afterRecovery: postRecovery.throughput.overallThroughput,\n                degradationPercent: ((preFailure.throughput.overallThroughput - duringFailure.throughput.overallThroughput) / preFailure.throughput.overallThroughput) * 100,\n                recoveryPercent: ((postRecovery.throughput.overallThroughput - preFailure.throughput.overallThroughput) / preFailure.throughput.overallThroughput) * 100\n            },\n            errorImpact: {\n                duringFailureRate: duringFailure.errors?.rate || 0,\n                acceptableThreshold: this.failureConfig.failureThresholds.maxErrorRate\n            }\n        };\n    }\n    \n    analyzeRecoveryCharacteristics(results) {\n        return {\n            recoveryTime: results.recovery.recoveryTime,\n            targetRecoveryTime: this.failureConfig.failureThresholds.recoveryTimeMs,\n            recoverySuccess: results.recovery.stabilityAchieved,\n            stabilityPeriod: this.failureConfig.recoveryValidation.stabilityPeriodMs,\n            fullRecoveryAchieved: this.isPerformanceRecovered(results.recovery.finalMetrics)\n        };\n    }\n    \n    checkFailureCompliance(results) {\n        const impact = this.analyzePerformanceImpact(results);\n        const recovery = this.analyzeRecoveryCharacteristics(results);\n        \n        return {\n            failureHandling: {\n                latencyWithinThreshold: impact.latencyImpact.duringFailure <= this.failureConfig.failureThresholds.maxLatencyMs,\n                throughputWithinThreshold: impact.throughputImpact.duringFailure >= this.failureConfig.failureThresholds.minThroughput,\n                errorRateWithinThreshold: impact.errorImpact.duringFailureRate <= this.failureConfig.failureThresholds.maxErrorRate\n            },\n            recoveryPerformance: {\n                recoveryTimeCompliant: recovery.recoveryTime <= recovery.targetRecoveryTime,\n                stabilityAchieved: recovery.recoverySuccess,\n                fullRecoveryCompliant: recovery.fullRecoveryAchieved\n            },\n            overallCompliance: {\n                gracefulDegradation: true, // Will be determined based on specific criteria\n                acceptableRecovery: recovery.recoveryTime <= recovery.targetRecoveryTime && recovery.fullRecoveryAchieved\n            }\n        };\n    }\n    \n    generateFailureRecommendations(results) {\n        const recommendations = [];\n        const compliance = this.checkFailureCompliance(results);\n        const impact = this.analyzePerformanceImpact(results);\n        \n        // Recovery time recommendations\n        if (!compliance.recoveryPerformance.recoveryTimeCompliant) {\n            recommendations.push({\n                category: 'recovery',\n                priority: 'high',\n                issue: `Recovery time ${results.recovery.recoveryTime}ms exceeds target ${this.failureConfig.failureThresholds.recoveryTimeMs}ms`,\n                recommendation: 'Implement faster failure detection and recovery mechanisms'\n            });\n        }\n        \n        // Performance degradation recommendations\n        if (impact.latencyImpact.degradationPercent > 300) { // 300% degradation\n            recommendations.push({\n                category: 'resilience',\n                priority: 'high',\n                issue: `Latency degraded by ${impact.latencyImpact.degradationPercent.toFixed(1)}% during failure`,\n                recommendation: 'Implement circuit breakers and fallback mechanisms'\n            });\n        }\n        \n        // Error handling recommendations\n        if (impact.errorImpact.duringFailureRate > impact.errorImpact.acceptableThreshold) {\n            recommendations.push({\n                category: 'reliability',\n                priority: 'medium',\n                issue: `Error rate ${impact.errorImpact.duringFailureRate.toFixed(2)}% exceeds acceptable threshold`,\n                recommendation: 'Improve error handling and graceful degradation'\n            });\n        }\n        \n        return recommendations;\n    }\n    \n    // ===== Comprehensive Failure Testing Suite =====\n    \n    async runComprehensiveFailureTests() {\n        console.log('🧪 Running comprehensive failure testing suite...');\n        \n        const results = {};\n        \n        // Run all failure scenarios\n        for (const scenarioName of Object.keys(this.failureConfig.scenarios)) {\n            console.log(`\\n🔄 Running scenario: ${scenarioName}`);\n            \n            try {\n                results[scenarioName] = await this.runFailureScenario(scenarioName);\n                \n                // Wait between scenarios for system stabilization\n                await this.sleep(30000);\n            } catch (err) {\n                console.error(`❌ Scenario ${scenarioName} failed:`, err.message);\n                results[scenarioName] = {\n                    error: err.message,\n                    timestamp: Date.now()\n                };\n            }\n        }\n        \n        // Generate comprehensive analysis\n        const comprehensiveAnalysis = this.analyzeComprehensiveFailureResults(results);\n        \n        // Store results\n        await this.storeComprehensiveFailureResults(results, comprehensiveAnalysis);\n        \n        console.log('✅ Comprehensive failure testing completed');\n        return { results, analysis: comprehensiveAnalysis };\n    }\n    \n    analyzeComprehensiveFailureResults(results) {\n        const scenarios = Object.keys(results).filter(key => !results[key].error);\n        const failedScenarios = Object.keys(results).filter(key => results[key].error);\n        \n        // Calculate overall resilience metrics\n        const recoveryTimes = scenarios.map(s => results[s].recoveryAnalysis?.recoveryTime || 0);\n        const latencyDegradations = scenarios.map(s => results[s].performanceImpact?.latencyImpact?.degradationPercent || 0);\n        \n        return {\n            summary: {\n                totalScenarios: Object.keys(results).length,\n                successfulScenarios: scenarios.length,\n                failedScenarios: failedScenarios.length,\n                overallSuccessRate: (scenarios.length / Object.keys(results).length) * 100\n            },\n            resilience: {\n                averageRecoveryTime: recoveryTimes.reduce((sum, time) => sum + time, 0) / recoveryTimes.length,\n                maxRecoveryTime: Math.max(...recoveryTimes),\n                averageLatencyDegradation: latencyDegradations.reduce((sum, deg) => sum + deg, 0) / latencyDegradations.length,\n                maxLatencyDegradation: Math.max(...latencyDegradations)\n            },\n            recommendations: this.generateComprehensiveRecommendations(results),\n            resilienceScore: this.calculateResilienceScore(results)\n        };\n    }\n    \n    calculateResilienceScore(results) {\n        let score = 0;\n        const maxScore = 100;\n        \n        const scenarios = Object.keys(results).filter(key => !results[key].error);\n        \n        // Success rate (0-30 points)\n        const successRate = scenarios.length / Object.keys(results).length;\n        score += successRate * 30;\n        \n        // Recovery time (0-35 points)\n        const avgRecoveryTime = scenarios.reduce((sum, s) => sum + (results[s].recoveryAnalysis?.recoveryTime || 0), 0) / scenarios.length;\n        if (avgRecoveryTime <= 10000) score += 35; // 10 seconds\n        else if (avgRecoveryTime <= 30000) score += 25; // 30 seconds\n        else if (avgRecoveryTime <= 60000) score += 15; // 1 minute\n        \n        // Performance degradation (0-35 points)\n        const avgDegradation = scenarios.reduce((sum, s) => sum + (results[s].performanceImpact?.latencyImpact?.degradationPercent || 0), 0) / scenarios.length;\n        if (avgDegradation <= 100) score += 35; // 100% degradation\n        else if (avgDegradation <= 300) score += 25; // 300% degradation\n        else if (avgDegradation <= 500) score += 15; // 500% degradation\n        \n        return {\n            score: Math.round(score),\n            maxScore,\n            grade: this.getResilienceGrade(score),\n            breakdown: {\n                successRate: successRate * 30,\n                recoveryTime: score >= 60 ? 35 : (score >= 50 ? 25 : 15),\n                degradation: score >= 85 ? 35 : (score >= 70 ? 25 : 15)\n            }\n        };\n    }\n    \n    getResilienceGrade(score) {\n        if (score >= 90) return 'A+';\n        if (score >= 80) return 'A';\n        if (score >= 70) return 'B+';\n        if (score >= 60) return 'B';\n        if (score >= 50) return 'C+';\n        return 'F';\n    }\n    \n    // ===== Utility Methods =====\n    \n    getCurrentMemoryUsageMB() {\n        return Math.round(process.memoryUsage().heapUsed / 1024 / 1024);\n    }\n    \n    sleep(ms) {\n        return new Promise(resolve => setTimeout(resolve, ms));\n    }\n    \n    async storeFailureResults(testId, analysis) {\n        try {\n            await this.redisClient.hSet('perf:failure:results', testId, JSON.stringify({\n                analysis,\n                timestamp: Date.now()\n            }));\n        } catch (err) {\n            console.error('Failed to store failure results:', err.message);\n        }\n    }\n    \n    async storeComprehensiveFailureResults(results, analysis) {\n        const reportId = `comprehensive_failure_${Date.now()}`;\n        \n        try {\n            await this.redisClient.hSet('perf:failure:comprehensive', reportId, JSON.stringify({\n                results,\n                analysis,\n                timestamp: Date.now()\n            }));\n            \n            console.log(`💾 Comprehensive failure results stored: ${reportId}`);\n        } catch (err) {\n            console.error('Failed to store comprehensive failure results:', err.message);\n        }\n    }\n    \n    async cleanup() {\n        if (this.testSuite) {\n            await this.testSuite.cleanup();\n        }\n        \n        if (this.redisClient) {\n            await this.redisClient.quit();\n        }\n        \n        if (this.backupRedisClient) {\n            await this.backupRedisClient.quit();\n        }\n        \n        if (this.pgClient) {\n            await this.pgClient.end();\n        }\n        \n        console.log('🧹 Performance Failure Scenarios cleanup completed');\n    }\n}\n\nmodule.exports = PerformanceFailureScenarios;\n\n// CLI interface\nif (require.main === module) {\n    const failureTests = new PerformanceFailureScenarios();\n    \n    async function runFailureTestsCLI() {\n        try {\n            await failureTests.init();\n            \n            const command = process.argv[2] || 'comprehensive';\n            const scenario = process.argv[3];\n            \n            switch (command) {\n                case 'scenario':\n                    if (!scenario) {\n                        console.log('Available scenarios:', Object.keys(failureTests.failureConfig.scenarios));\n                        return;\n                    }\n                    console.log(`🧪 Running single failure scenario: ${scenario}`);\n                    const result = await failureTests.runFailureScenario(scenario);\n                    console.log('📊 Failure Test Results:', JSON.stringify(result, null, 2));\n                    break;\n                    \n                case 'comprehensive':\n                default:\n                    console.log('🧪 Running comprehensive failure testing...');\n                    const comprehensiveResults = await failureTests.runComprehensiveFailureTests();\n                    console.log('📊 Comprehensive Results:', JSON.stringify(comprehensiveResults.analysis, null, 2));\n                    break;\n            }\n            \n        } catch (err) {\n            console.error('❌ Failure testing failed:', err);\n        } finally {\n            await failureTests.cleanup();\n            process.exit(0);\n        }\n    }\n    \n    runFailureTestsCLI();\n}

<system-reminder>
Whenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.
</system-reminder>
</output>
</result>